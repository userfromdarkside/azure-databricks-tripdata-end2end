{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de5c0bc0",
   "metadata": {},
   "source": [
    "databricks notebook4: create Driver dimension table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a429989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spark.sql.functions import monotonically_increasing_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a98f7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_path = \"abfss://trip-data@<your-storage-account>.dfs.core.windows.net/silver/trip_transactions\"\n",
    "trip_df = spark.read.format('delta').load(trip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4a3de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_df = trip_df.select('driver_id','driver_name').dropDuplicates(['driver_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad455c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add surrogate key, and create driver dimension dataframe\n",
    "dim_driver = driver_df.withColumn('KeydriverID',monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c1d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns\n",
    "dim_driver = dim_driver.select('KeydriverID','driver_id','driver_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87435d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to silver layer\n",
    "dim_driver.write.format('delta').mode('overwrite').save(\"abfss://trip-data@<your-storage-account>.dfs.core.windows.net/silver/dim_driver\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
